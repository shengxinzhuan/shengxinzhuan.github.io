<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://shengxinzhuan.github.io/</id>
    <title>生信撰的博客</title>
    <updated>2019-09-11T05:12:35.785Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://shengxinzhuan.github.io/"/>
    <link rel="self" href="https://shengxinzhuan.github.io//atom.xml"/>
    <subtitle>never stop playing！！！</subtitle>
    <logo>https://shengxinzhuan.github.io//images/avatar.png</logo>
    <icon>https://shengxinzhuan.github.io//favicon.ico</icon>
    <rights>All rights reserved 2019, 生信撰的博客</rights>
    <entry>
        <title type="html"><![CDATA[【线代学习笔记】Having Solution or Not]]></title>
        <id>https://shengxinzhuan.github.io//post/xian-dai-xue-xi-bi-ji-having-solution-or-not</id>
        <link href="https://shengxinzhuan.github.io//post/xian-dai-xue-xi-bi-ji-having-solution-or-not">
        </link>
        <updated>2019-09-11T04:36:17.000Z</updated>
        <content type="html"><![CDATA[<p><img src="https://shengxinzhuan.github.io//post-images/1568177342650.jpg" alt=""><br>
如果有解，那有几个解，如果有一个解，那么就称为unique solution，如果有无穷多个解，则称为infinite solution。<br>
那么如何知道是否有解，是这节课讨论的一个话题。<br>
假设我们手上有n个向量，他们都是线性相关（linear dependent）的，则存在n个非全零的数，使他们相加为0<br>
如果是线性无关（linear independent），则要令其相加为0，则只能这n个数都是0<br>
特殊情况，0向量与其他向量是线性相关<br>
<img src="https://shengxinzhuan.github.io//post-images/1568177989471.png" alt=""><br>
如果column A 是线性相关的，则Ax=b会有解，并且是无穷多，反之毅然。<br>
<img src="https://shengxinzhuan.github.io//post-images/1568178178381.jpg" alt=""><br>
<img src="https://shengxinzhuan.github.io//post-images/1568178216788.jpg" alt=""><br>
什么是rank<br>
矩阵的秩（rank）指的是矩阵A的列秩是A的线性独立的纵列的极大数，通常表示为r(A)，rk(A)或rank A。<br>
矩阵的行最简式（Nullity）=Number of columns -Rank<br>
<img src="https://shengxinzhuan.github.io//post-images/1568178688742.jpg" alt=""><br>
<img src="https://shengxinzhuan.github.io//post-images/1568178728665.jpg" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【生信小课堂】snp calling之后hard-filter的参数选择]]></title>
        <id>https://shengxinzhuan.github.io//post/sheng-xin-xiao-ke-tang-snp-calling-zhi-hou-hard-filter-de-can-shu-xuan-ze</id>
        <link href="https://shengxinzhuan.github.io//post/sheng-xin-xiao-ke-tang-snp-calling-zhi-hou-hard-filter-de-can-shu-xuan-ze">
        </link>
        <updated>2019-09-06T05:17:03.000Z</updated>
        <content type="html"><![CDATA[<p>现在随着三代测序价格跟重测序价格的持续走低，越来越多的全基因组等级的群体遗传文章持续发布。而当拿到一批raw data之后，通常是需要经过一系列是上游分析处理使之成为可以操作的下游raw data，这个过程就是我们经常说的snp calling的过程。对于snp是如何得到的，这里我推荐基因所明哥的一篇博文。<br>
https://ming-lian.github.io/2019/02/08/call-snp/<br>
该篇博文将gatk的流程说得很透彻，各位如果需要可以仔细研读一番。<br>
对于模式生物，我们可以使用VQSR的方法进行过滤。但对于非模式生物，没有现成的snp库，通常我们都是使用hard-filter的方式进行过滤，对于参数的选择，gatk的官方给出了推荐参数，但往往推荐参数并不适合我们手头上的数据类型。如果snp过滤不当，下游的分析会异常难以进行（特指这个倒霉催返回来重新过滤一遍的我）。<br>
在明哥的博文里面，我们可以看到这样的几张图<br>
<img src="https://shengxinzhuan.github.io//post-images/1567747943699.png" alt=""><br>
<img src="https://shengxinzhuan.github.io//post-images/1567747966412.png" alt=""><br>
这几张图便是我们进行过滤参数选择的主要依据，掌握好这几张图的做法，对于我们过滤的时候至关重要。<br>
这里介绍的方法是我这两天的劳动成果，在这里再次感谢无私的鲍大哥带我跨过坑。<br>
第一步，我们需要从raw vcf文件中得到我们需要的信息，这里以提取QD这个值为例。</p>
<pre><code>###使用bcftools的query模块进行提取(提取FS就将QD改为FS即可)
bcftools query -f &quot;%QD\n&quot; raw_snp.vcf &gt; my_snp.QD
</code></pre>
<p>这样我们就得到了vcf文件中的QD值，接着我们需要把提取得到的QD值里面的.去掉，不然在作图的时候会提示报错，这里我使用python进行过滤</p>
<pre><code>###vim clean_point.py
import sys
x = sys.argv[1]
file = open(x, &quot;r&quot;)
lines = file.readlines()
for line in lines:
     if str(line) != &quot;.\n&quot;:
		    print(line.rstrip())
###python clean_point.py my_snp.QD &gt; clean_snp.QD
</code></pre>
<p>完成过滤之后，我们就可以导进r或者python作图，这里两种方法都介绍一下<br>
首先是python(本操作在jupyter里面进行)</p>
<pre><code>###引入模块
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
###导入数据
df = pd.read_csv(&quot;clean_snp.QD&quot;,names=&quot;Q&quot;)
sns.kdeplot(df[&quot;Q&quot;], shade=True)
</code></pre>
<p><img src="https://shengxinzhuan.github.io//post-images/1567748974860.png" alt=""><br>
接着就是R</p>
<pre><code>library(ggplot2)
snp_QD &lt;- read.table(&quot;clean_snp.QD&quot;,header = FALSE)
names(snp_QD) &lt;- (&quot;Q&quot;)
ggplot(aes(x=Q###此处就是你要输入的那一列的列名，不要加双引号，我早上就是因为加双引号没出图，后面是潜哥帮我指出错误)，data = snp_QD) + geom_density()
</code></pre>
<p><img src="https://shengxinzhuan.github.io//post-images/1567749243864.png" alt=""><br>
其他的也是照着画就行，最后还是再次感谢这两天帮过我的各位~</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【线代学习笔记】向量与矩阵的乘法（Matrix-Vector Product）]]></title>
        <id>https://shengxinzhuan.github.io//post/xian-dai-xue-xi-bi-ji-xiang-liang-yu-ju-zhen-de-cheng-fa-matrix-vector-product</id>
        <link href="https://shengxinzhuan.github.io//post/xian-dai-xue-xi-bi-ji-xiang-liang-yu-ju-zhen-de-cheng-fa-matrix-vector-product">
        </link>
        <updated>2019-09-06T05:09:01.000Z</updated>
        <content type="html"><![CDATA[<p>前言：学不求一次之多，而贵在周周复省。虽然时间很零碎，但也不强求自己能一天学多少，争取每天积累一点就行。<br>
教程：李宏毅（Hung-yi Lee）的Linear Equations视频教程<br>
ppt地址：http://speech.ee.ntu.edu.tw/~tlkagk/courses_LA18.html<br>
视频地址：https://www.bilibili.com/video/av31780632/?p=5<br>
由于想系统而深入学习机器学习的东西，所以将本科没有上过的线代学习一下，所以才有了这个读书笔记。<br>
一开始看到这个英文标题其实有点懵逼，Matrix-Vector product，什么东西来着？？？<br>
后面看到这张图，才意识到是在讲什么东西<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746635779.jpg" alt=""><br>
原来是讲矩阵与向量相乘<br>
那么怎么理解这个东西呢？<br>
本来我个人的理解是这样的，矩阵A相对于向量x，其实是一个高维跟低维的，就类似面跟点的关系，通过与A相乘，就是将x以A的维度去衡量x，使得x的有一个更直观的结果呈现在面前。<br>
后面李老师提到了Linear System的思维去理解这个东西<img src="https://shengxinzhuan.github.io//post-images/1567746657377.jpg" alt=""><br>
emmm，果然是类似的东西<br>
而后李老师又从两个角度对product进行了阐述，分别是row aspect跟column aspect两个层面。</p>
<pre><code>###以解这个两个未知数组的题目为例
x1+4x2=b1
-3x1+2x2 = b2
###这个东西其实就是可以写成矩阵跟向量的相乘的形式
A=[(1，4)(-3，2)]
###而向量则是x1与x2所组成的
x=（x1，x2）
###将x投进A这个Linear System里面，那么当x1等于-2，x2等于0.5时，如何进行评价
</code></pre>
<p>首先是Row aspect<img src="https://shengxinzhuan.github.io//post-images/1567746673135.jpg" alt=""><br>
由于row1与x垂直，所以b1明显就为0，而row2与x相乘，结果为7，故而b2就为7<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746687775.jpg" alt=""><br>
让row1与x相乘，得到（-2,6），让row2跟x相乘，得到（2,1），将这两个向量合起来，正好也是（0,7）<br>
虽然角度不一样，但最终结果是一致的，而计算过程其实正是在矩阵的某一维度中分解之后取合并，这个过程其实理解了就不会很懵逼。<br>
而矩阵能与向量相乘的前提条件，两者必须是matched的，其实也很好理解，只有在矩阵最低维度与向量相同时，两者才可能在一个向量空间中进行运算。<br>
接着就是一些运算的法则，这个其实也蛮容易理解的<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746708320.jpg" alt=""><br>
最后的话，提到了一个比较有意识的法则，即Ax=Bx，则A与B是相等的，这个其实我还不怎么理解，回头再查查资料</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【线代学习笔记】向量（vector）与矩阵（matrix）]]></title>
        <id>https://shengxinzhuan.github.io//post/xian-dai-xue-xi-bi-ji-xiang-liang-vectoryu-ju-zhen-matrix</id>
        <link href="https://shengxinzhuan.github.io//post/xian-dai-xue-xi-bi-ji-xiang-liang-vectoryu-ju-zhen-matrix">
        </link>
        <updated>2019-09-06T05:03:11.000Z</updated>
        <content type="html"><![CDATA[<p>前言：学不求一次之多，而贵在周周复省。虽然时间很零碎，但也不强求自己能一天学多少，争取每天积累一点就行。<br>
教程：李宏毅（Hung-yi Lee）的Linear Equations视频教程<br>
ppt地址：http://speech.ee.ntu.edu.tw/~tlkagk/courses_LA18.html<br>
视频地址：https://www.bilibili.com/video/av31780632/?p=5<br>
由于想系统而深入学习机器学习的东西，所以将本科没有上过的线代学习一下，所以才有了这个读书笔记。<br>
【向量】<br>
什么是向量？<br>
最简单的理解就是，一组数字的集合（a set of numbers）<br>
按照行列分法，既可以分为行向量（Row vector）以及列向量（column vector）<br>
向量的表示方法<img src="https://shengxinzhuan.github.io//post-images/1567746379794.png" alt=""><br>
假定某向量为V，里面有n个元素，那么按照顺序，既可以将向量中的元素表示为V1，V2......Vn<br>
当向量的元素少于4个的时候，既可以在平面上以几何的形式表示出来，既一维到三维的表示方法<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746393586.png" alt=""><br>
向量的运算<br>
数乘运算（scalar multiplication）<br>
类似于int类型数字的乘法，只不过是vector里面所有的components都与某个数相乘。</p>
<pre><code>v = [1,2,3,4]
c =5
###此时v的数乘运算表示为cv，而其运算也是十分简单的
cv = [1*5,2*5,3*5,4*5]
</code></pre>
<p>向量的加法（vector addition）<br>
其实向量的加减是一个道理，即相应向量分量的加减，如何从字面理解这个意思，其实就是类似我们初高中物理里面的正交分解，力F1可以在二维轴上分解出F1x与F1y，力F2可以在二维轴上分解出F2x与F2y，然后在这个分解的坐标轴中，得到了一个很好的映射，从而将两者在该坐标轴上的关系理清，然后通过简单的加减，即可得到最后作用的结果。图例如下<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746409147.png" alt=""><br>
向量的集合（vector set）<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746423183.png" alt=""><br>
由不同的向量组合在一起，组成向量集合，如何理解，我们可以以只有两个元素的二维向量来简单的理解一下。<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746435617.png" alt=""><br>
那么如何来表示这个集合呢，我们通常将这个集合以大写字母R表示，如果是2维的，表示为R2，如果是三维的，则为R3，以此类推<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746449814.png" alt=""><br>
那么集合间是如何运算的呢？<br>
首先，我们的运算必须是同一维度的，拿2维跟3维的进行运算，这有点超出想象。<br>
那么这个集合的运算符合什么定律呢，看下图<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746465812.png" alt=""><br>
<img src="https://shengxinzhuan.github.io//post-images/1567746476031.png" alt=""><br>
【矩阵】<br>
什么是矩阵？<br>
矩阵，就是一组向量的集合，也就是上面的vector set<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746487641.png" alt=""><br>
矩阵的表示<br>
如果某矩阵有m行n列，那么我们就可以将其表示为Mmxn。记住一个原则<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746495905.png" alt=""><br>
如何表示矩阵中的某个元素，其实也是先行后列的表示方法A矩阵的第三行，第四列的元素，表示为A34<br>
矩阵的运算<br>
首先是加减法，其实这很好理解，同一维度的才能进行加减，即两个矩阵具有相同的行列时才具备加减的条件<br>
接着是数乘，其实就是向量数乘的延伸。<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746510575.png" alt=""><br>
特殊矩阵，Zero matrix，顾名思义，都是0，可以表示为Omxn，个人认为，这就是一个多维空间中的一个奇点，有点奇妙<br>
Identity matrix，除了对角线，其余都是零，这个也是很奇妙，在一个大于1的多维空间中，它是一条线（个人yy，不一定正确）<br>
矩阵的转置（Transpose）<br>
简而言之，就是行列互换（包括元素），个人觉得，这个类似于左右手的关系，即轴对称，在三维空间里，应该就是镜像的存在<br>
<img src="https://shengxinzhuan.github.io//post-images/1567746525242.png" alt=""><br>
<img src="https://shengxinzhuan.github.io//post-images/1567746533883.png" alt=""><br>
视频看了一个小时，然后对着ppt边敲字边截图，又过了一个小时，果然还是有点累</p>
]]></content>
    </entry>
</feed>